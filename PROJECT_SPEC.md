# Production-Ready System Architecture: Realtime AI Customer Support

## ğŸ“‹ Project Overview

A secure, scalable, high-availability AI-powered customer support system combining Retrieval-Augmented Generation (RAG), real-time product data, and conversational intelligence.

---

## ğŸ—ï¸ Production-Grade System Architecture

```mermaid
graph TD
    subgraph Frontend
        A1[Web App (React/TS)]
        A2[Socket.io Client]
    end

    subgraph API Layer
        B1[Web/API Gateway (Nginx)]
        B2[FastAPI (Uvicorn)]
    end

    subgraph Services
        C1[RAG Orchestrator]
        C2[LLM Service (OpenAI, GPT-4/4o)]
        C3[Retrieval Service (Qdrant/Semantic Search)]
        C4[Rerank Service (Cohere)]
        C5[Intent Classification Service (HuggingFace)]
        C6[Session State (Redis)]
        C7[Product Data API/Adapter]
    end

    subgraph Data Layer
        D1[PostgreSQL (User, Ticket, Audit)]
        D2[Qdrant (Vector DB)]
        D3[Object Storage (S3/MinIO)]
        D4[Redis Cache]
    end

    subgraph Monitoring & Ops
        E1[Sentry (APM + Error Tracking)]
        E2[Prometheus/Grafana (Metrics)]
        E3[Logging (Structured)]
        E4[CI/CD (GitHub Actions)]
    end

    A1 -->|HTTPS/WebSocket| B1 --> B2
    A2 -->|WebSocket| B2

    B2 -->|REST/WebSocket| C1
    C1 -->|Async| C2 & C3 & C5

    C3 -->|Query| D2
    C2 -->|API| [OpenAI Cloud]
    C3 -->|Rerank| C4
    C1 -->|State| C6
    C1 -->|Product/Order| C7
    C7 -->|Product Info| D1
    C1 -->|Storage| D3
    C1 -->|Cache| D4

    B2 -->|Logs| E3
    C1 -->|Metrics| E2
    B2 -->|Errors| E1

    E4-.->|Deploy| B2 & C1 & C3 & D1 & D2

```

**Key Features:**
- API Gateway handles routing, security, throttling.
- FastAPI enables async REST and real-time WebSocket endpoints.
- Modular microservices for LLM, retrieval, ranking, and intent detection.
- Fully containerized and deployable on Kubernetes, Docker Compose, or managed cloud platforms.
- Extensive observability and secure API key management.

---

## ğŸ“¦ Production Folder Structure

```
realtime-ai-support/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry
â”‚   â”‚   â”œâ”€â”€ config.py               # Env & secret config
â”‚   â”‚   â”œâ”€â”€ dependencies.py         # Dependency wire-up
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py             # Chat REST endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ websocket.py        # Real-time endpoints
â”‚   â”‚   â”‚   â””â”€â”€ admin.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_orchestrator.py # Pipeline entrypoint
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocess.py       # Query cleaning/expansion
â”‚   â”‚   â”‚   â”œâ”€â”€ intent.py           # Intent classifier
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py        # Hybrid retriever (FAQ/Product)
â”‚   â”‚   â”‚   â”œâ”€â”€ rerank.py           # Cohere reranker
â”‚   â”‚   â”‚   â”œâ”€â”€ context_opt.py      # Token budgeting/attribution
â”‚   â”‚   â”‚   â””â”€â”€ llm.py              # Call to OpenAI/GPT
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ postgres.py         # SQLAlchemy ORM models
â”‚   â”‚   â”‚   â””â”€â”€ migrations/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ticket.py
â”‚   â”‚   â”‚   â””â”€â”€ conversation.py
â”‚   â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ qdrant.py           # Vector DB operations
â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ redis_cache.py      # Query/result caching
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â”‚   â”œâ”€â”€ monitoring.py
â”‚   â”‚   â”‚   â””â”€â”€ compression.py
â”‚   â”‚   â””â”€â”€ settings/
â”‚   â”‚       â””â”€â”€ secrets.py          # API keys (never in Git!)
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_chat.py
â”‚   â”‚   â”œâ”€â”€ test_rag.py
â”‚   â”‚   â””â”€â”€ test_intent.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ faqs/
â”‚   â”‚   â”œâ”€â”€ products/
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”‚       â””â”€â”€ ingest_docs.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWidget.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageList.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ InputBox.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TypingIndicator.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useChat.ts
â”‚   â”‚   â”‚   â””â”€â”€ useWebSocket.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ docker-compose.yaml
â”‚   â”œâ”€â”€ k8s/
â”‚   â”‚   â””â”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â”œâ”€â”€ nginx/
â”‚   â”‚   â””â”€â”€ nginx.conf
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ register_services.sh
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh
â”‚   â”œâ”€â”€ seed_data.py
â”‚   â””â”€â”€ benchmark.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â””â”€â”€ ARCHITECTURE.md
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml
â”‚       â””â”€â”€ deploy.yml
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

### ğŸ—ï¸ Structural Notes

- **Backend** is modular, with clear separation of concerns per microservice-like layers (api, services, data/models, vector store, caching, utils, settings).
- **Frontend** (React + TypeScript) is designed for scalability, with dedicated folders for components, hooks, services, and type definitions.
- **Infrastructure** contains Docker, Kubernetes, Nginx, and observability config for easy CI/CD and cloud-native deployment.
- **All secrets (API keys etc) must reside in settings/secrets.py or environment variables; never checked into source control.**

---

## ğŸ”’ Security & Compliance

- API keys and credentials loaded only from environment/configs outside source.
- All inter-service communication secured via HTTPS/mTLS in production.
- Rate-limiting, request validation, session/CSRF protections at API Gateway.
- All user PII, logs, and data in compliance with GDPR/CCPA via encrypted storage.

---

## ğŸš¦ Observability

- **Sentry** for end-to-end error and performance monitoring.
- **Prometheus/Grafana** to record API, retrieval, and LLM/adapter service metrics.
- **Structured logging** for audit trails and incident traceability.

---

## ğŸ”„ Production Workflow

1. **User interacts with React widget** â†’ API Gateway â†’ Web/API server (FastAPI).
2. **Request is routed to RAG Orchestrator**, which:
    - Cleans/preprocesses query, classifies intent.
    - Executes parallel retrieval (FAQ/product), applies Cohere re-ranking.
    - Tokenizes, budgets, and attributes sources for LLM prompt context.
    - Calls LLM API (OpenAI) and streams/caches response.
3. **All data & context is monitored, logged, and optionally cached** for performance.
4. **Response delivered back to frontend with source attributions and confidence indicators.**

---

## ğŸ“‚ Example Environment Variables

```bash
# .env.example
OPENAI_API_KEY=sk-xxxx
COHERE_API_KEY=xxxx
QDRANT_URL=http://qdrant:6333
QDRANT_API_KEY=xxxx
REDIS_URL=redis://redis:6379
POSTGRES_URL=postgresql://user:password@postgres:5432/supportdb

RAG_MAX_CONTEXT_TOKENS=3000
RAG_TOP_K=5
RAG_RERANK_TOP_N=5
RAG_CACHE_TTL=300

EMBEDDING_MODEL=all-MiniLM-L6-v2
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=500
SENTRY_DSN=xxxx
```

---

## âœ… Ready for Production

- All folders, configs, and patterns align to containerized production best practices.
- Subsystems are decoupled, tested, and observable.
- Ready for CI/CD automation and cloud scaling.

For implementation details, see `/docs/ARCHITECTURE.md` and `/backend/app/services/*`.

